{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Eigenfaces - PCA for Face Recognition\n",
                "\n",
                "Applying PCA to face images:\n",
                "1. Load face dataset\n",
                "2. Apply PCA\n",
                "3. Visualize eigenfaces\n",
                "4. Reconstruct faces\n",
                "5. Face recognition\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.datasets import fetch_olivetti_faces\n",
                "from sklearn.decomposition import PCA\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "sns.set_style('white')\n",
                "plt.rcParams['figure.figsize'] = (12, 6)\n",
                "np.random.seed(42)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Load Olivetti Faces Dataset\n",
                "\n",
                "400 face images (64x64 pixels) of 40 people."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load dataset\n",
                "faces_data = fetch_olivetti_faces(shuffle=True, random_state=42)\n",
                "faces = faces_data.data\n",
                "face_images = faces_data.images\n",
                "n_samples, h, w = face_images.shape\n",
                "\n",
                "print(f'Dataset: {n_samples} images')\n",
                "print(f'Image size: {h}x{w} = {h*w} pixels')\n",
                "print(f'Data matrix shape: {faces.shape}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Visualize Sample Faces"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(2, 6, figsize=(12, 4))\n",
                "for i, ax in enumerate(axes.ravel()):\n",
                "    ax.imshow(face_images[i], cmap='gray')\n",
                "    ax.axis('off')\n",
                "plt.suptitle('Sample Faces from Olivetti Dataset', fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Apply PCA\n",
                "\n",
                "Reduce from 4096 dimensions to much fewer."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Apply PCA\n",
                "n_components = 150\n",
                "pca = PCA(n_components=n_components, whiten=True)\n",
                "faces_pca = pca.fit_transform(faces)\n",
                "\n",
                "print(f'Original dimensions: {faces.shape}')\n",
                "print(f'Reduced dimensions: {faces_pca.shape}')\n",
                "print(f'Variance explained: {np.sum(pca.explained_variance_ratio_)*100:.2f}%')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Variance Explained"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.plot(cumsum, linewidth=2)\n",
                "plt.axhline(y=0.95, color='r', linestyle='--', label='95% variance')\n",
                "plt.axhline(y=0.99, color='orange', linestyle='--', label='99% variance')\n",
                "plt.xlabel('Number of Components', fontsize=12)\n",
                "plt.ylabel('Cumulative Variance Explained', fontsize=12)\n",
                "plt.title('How Many Eigenfaces Do We Need?', fontsize=14, fontweight='bold')\n",
                "plt.legend()\n",
                "plt.grid(True, alpha=0.3)\n",
                "plt.show()\n",
                "\n",
                "# Find how many for 95% and 99%\n",
                "n_95 = np.argmax(cumsum >= 0.95) + 1\n",
                "n_99 = np.argmax(cumsum >= 0.99) + 1\n",
                "print(f'Components for 95% variance: {n_95}')\n",
                "print(f'Components for 99% variance: {n_99}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Visualize Eigenfaces\n",
                "\n",
                "Eigenvectors reshaped into images."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get eigenfaces (principal components)\n",
                "eigenfaces = pca.components_.reshape((n_components, h, w))\n",
                "\n",
                "# Plot first 15 eigenfaces\n",
                "fig, axes = plt.subplots(3, 5, figsize=(12, 7))\n",
                "for i, ax in enumerate(axes.ravel()):\n",
                "    ax.imshow(eigenfaces[i], cmap='gray')\n",
                "    ax.set_title(f'Eigenface {i+1}', fontsize=10)\n",
                "    ax.axis('off')\n",
                "plt.suptitle('Top 15 Eigenfaces (Principal Components)', fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Observation**: Eigenfaces capture key facial features - lighting, expressions, orientations."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Reconstruct Faces with Different Components"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Choose a face to reconstruct\n",
                "face_idx = 0\n",
                "original_face = face_images[face_idx]\n",
                "\n",
                "# Reconstruct with different numbers of components\n",
                "n_components_list = [10, 25, 50, 100, 150]\n",
                "\n",
                "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
                "axes = axes.ravel()\n",
                "\n",
                "# Original\n",
                "axes[0].imshow(original_face, cmap='gray')\n",
                "axes[0].set_title('Original', fontsize=12, fontweight='bold')\n",
                "axes[0].axis('off')\n",
                "\n",
                "# Reconstructions\n",
                "for i, n_comp in enumerate(n_components_list):\n",
                "    pca_temp = PCA(n_components=n_comp)\n",
                "    pca_temp.fit(faces)\n",
                "    \n",
                "    # Transform and inverse transform\n",
                "    face_encoded = pca_temp.transform(faces[face_idx:face_idx+1])\n",
                "    face_reconstructed = pca_temp.inverse_transform(face_encoded)\n",
                "    face_reconstructed = face_reconstructed.reshape(h, w)\n",
                "    \n",
                "    var_exp = np.sum(pca_temp.explained_variance_ratio_) * 100\n",
                "    \n",
                "    axes[i+1].imshow(face_reconstructed, cmap='gray')\n",
                "    axes[i+1].set_title(f'{n_comp} components ({var_exp:.1f}% var)', fontsize=11)\n",
                "    axes[i+1].axis('off')\n",
                "\n",
                "plt.suptitle('Face Reconstruction with Different Numbers of Eigenfaces', fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Observation:\n",
                "- **10 components**: Blurry, captures basic structure\n",
                "- **25 components**: Recognizable\n",
                "- **50+ components**: Very close to original\n",
                "\n",
                "**Compression**: 64×64 = 4096 pixels → 50 numbers! (98.8% reduction)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Face Recognition with Eigenfaces"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Split data\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    faces, faces_data.target, test_size=0.25, random_state=42\n",
                ")\n",
                "\n",
                "# Apply PCA\n",
                "n_comp_recog = 100\n",
                "pca_recog = PCA(n_components=n_comp_recog, whiten=True)\n",
                "X_train_pca = pca_recog.fit_transform(X_train)\n",
                "X_test_pca = pca_recog.transform(X_test)\n",
                "\n",
                "print(f'Training set: {X_train.shape} → {X_train_pca.shape}')\n",
                "print(f'Test set: {X_test.shape} → {X_test_pca.shape}')\n",
                "\n",
                "# Simple nearest neighbor classifier\n",
                "def predict_face(X_train_pca, y_train, X_test_pca):\n",
                "    predictions = []\n",
                "    for test_face in X_test_pca:\n",
                "        # Find nearest neighbor in PCA space\n",
                "        distances = np.linalg.norm(X_train_pca - test_face, axis=1)\n",
                "        nearest_idx = np.argmin(distances)\n",
                "        predictions.append(y_train[nearest_idx])\n",
                "    return np.array(predictions)\n",
                "\n",
                "# Predict\n",
                "y_pred = predict_face(X_train_pca, y_train, X_test_pca)\n",
                "accuracy = np.mean(y_pred == y_test)\n",
                "\n",
                "print(f'\\nRecognition accuracy: {accuracy*100:.2f}%')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Visualize Predictions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Show some predictions\n",
                "fig, axes = plt.subplots(2, 5, figsize=(14, 6))\n",
                "for i, ax in enumerate(axes.ravel()):\n",
                "    test_face = X_test[i].reshape(h, w)\n",
                "    ax.imshow(test_face, cmap='gray')\n",
                "    \n",
                "    correct = y_test[i] == y_pred[i]\n",
                "    color = 'green' if correct else 'red'\n",
                "    ax.set_title(f'True: {y_test[i]}, Pred: {y_pred[i]}', color=color, fontsize=10)\n",
                "    ax.axis('off')\n",
                "\n",
                "plt.suptitle('Face Recognition Results (Green=Correct, Red=Wrong)', fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Summary\n",
                "\n",
                "### Eigenfaces Approach:\n",
                "1. **Collect** face images (flatten to vectors)\n",
                "2. **Apply PCA** to find eigenfaces\n",
                "3. **Project** faces into eigenface space (dimensionality reduction)\n",
                "4. **Store** low-dimensional representations\n",
                "5. **Recognize** by finding nearest neighbor in PCA space\n",
                "\n",
                "### Benefits:\n",
                "- **Compression**: 4096 → ~100 dimensions (97% reduction)\n",
                "- **Speed**: Faster comparisons in low-D space\n",
                "- **Noise reduction**: Captures essential features\n",
                "- **Works well**: High recognition accuracy\n",
                "\n",
                "### Limitations:\n",
                "- Sensitive to lighting and pose\n",
                "- Linear method (modern: use deep learning)\n",
                "- Requires aligned faces\n",
                "\n",
                "### Applications:\n",
                "- Face recognition systems\n",
                "- Face verification\n",
                "- Avatar generation\n",
                "- Video compression\n",
                "\n",
                "**Interview Tip**: \"Eigenfaces applies PCA to face images, treating each pixel as a feature. The eigenfaces capture key facial variations. By projecting into this low-dimensional space, we achieve massive compression (4096→100 dims) while maintaining recognition accuracy. It's a classic example of PCA for real-world dimensionality reduction.\""
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# PCA From Scratch\n",
                "\n",
                "Implementing Principal Component Analysis using only NumPy:\n",
                "1. Data standardization\n",
                "2. Covariance matrix computation\n",
                "3. Eigendecomposition\n",
                "4. Data transformation\n",
                "5.Comparison with sklearn\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.decomposition import PCA as SklearnPCA\n",
                "from sklearn.datasets import load_iris\n",
                "\n",
                "sns.set_style('darkgrid')\n",
                "plt.rcParams['figure.figsize'] = (12, 6)\n",
                "np.random.seed(42)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Load Data: Iris Dataset\n",
                "\n",
                "4 features, 3 classes - perfect for demonstrating PCA."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "iris = load_iris()\n",
                "X = iris.data\n",
                "y = iris.target\n",
                "feature_names = iris.feature_names\n",
                "\n",
                "print(f'Dataset: {X.shape[0]} samples, {X.shape[1]} features')\n",
                "print(f'Features: {feature_names}')\n",
                "print(f'Classes: {iris.target_names}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Step 1: Standardize the Data\n",
                "\n",
                "**Critical**: Features must have mean=0 and std=1."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def standardize(X):\n",
                "    mean = np.mean(X, axis=0)\n",
                "    std = np.std(X, axis=0)\n",
                "    X_standardized = (X - mean) / std\n",
                "    return X_standardized, mean, std\n",
                "\n",
                "X_std, mean, std = standardize(X)\n",
                "\n",
                "print('Original data:')\n",
                "print(f'Mean: {np.mean(X, axis=0)}')\n",
                "print(f'Std: {np.std(X, axis=0)}')\n",
                "print('\\nStandardized data:')\n",
                "print(f'Mean: {np.mean(X_std, axis=0)}')\n",
                "print(f'Std: {np.std(X_std, axis=0)}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Step 2: Compute Covariance Matrix\n",
                "\n",
                "$$\\Sigma = \\frac{1}{m}X^TX$$"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def compute_covariance_matrix(X):\n",
                "    m = X.shape[0]\n",
                "    # X already centered (mean=0 after standardization)\n",
                "    cov_matrix = (1/m) * X.T.dot(X)\n",
                "    return cov_matrix\n",
                "\n",
                "cov_matrix = compute_covariance_matrix(X_std)\n",
                "\n",
                "print('Covariance matrix shape:', cov_matrix.shape)\n",
                "print('\\nCovariance matrix:')\n",
                "print(cov_matrix)\n",
                "\n",
                "# Visualize\n",
                "plt.figure(figsize=(8, 6))\n",
                "sns.heatmap(cov_matrix, annot=True, fmt='.3f', cmap='coolwarm', \n",
                "           xticklabels=feature_names, yticklabels=feature_names)\n",
                "plt.title('Covariance Matrix', fontsize=14, fontweight='bold')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Step 3: Compute Eigenvalues and Eigenvectors"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def compute_eigen(cov_matrix):\n",
                "    eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
                "    \n",
                "    # Sort by eigenvalue (descending)\n",
                "    idx = eigenvalues.argsort()[::-1]\n",
                "    eigenvalues = eigenvalues[idx]\n",
                "    eigenvectors = eigenvectors[:, idx]\n",
                "    \n",
                "    return eigenvalues, eigenvectors\n",
                "\n",
                "eigenvalues, eigenvectors = compute_eigen(cov_matrix)\n",
                "\n",
                "print('Eigenvalues (variance in each PC):')\n",
                "print(eigenvalues)\n",
                "print('\\nEigenvectors (principal components):')\n",
                "print(eigenvectors)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Variance Explained"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def variance_explained(eigenvalues):\n",
                "    total_variance = np.sum(eigenvalues)\n",
                "    var_exp = eigenvalues / total_variance\n",
                "    cumulative_var_exp = np.cumsum(var_exp)\n",
                "    return var_exp, cumulative_var_exp\n",
                "\n",
                "var_exp, cum_var_exp = variance_explained(eigenvalues)\n",
                "\n",
                "for i in range(len(eigenvalues)):\n",
                "    print(f'PC{i+1}: {var_exp[i]*100:.2f}% (cumulative: {cum_var_exp[i]*100:.2f}%)')\n",
                "\n",
                "# Plot\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# Scree plot\n",
                "axes[0].bar(range(1, len(eigenvalues)+1), eigenvalues, alpha=0.7, color='steelblue')\n",
                "axes[0].set_xlabel('Principal Component', fontsize=12)\n",
                "axes[0].set_ylabel('Eigenvalue (Variance)', fontsize=12)\n",
                "axes[0].set_title('Scree Plot', fontsize=13, fontweight='bold')\n",
                "axes[0].grid(True, alpha=0.3)\n",
                "\n",
                "# Cumulative variance\n",
                "axes[1].plot(range(1, len(cum_var_exp)+1), cum_var_exp, 'o-', linewidth=2, markersize=8)\n",
                "axes[1].axhline(y=0.95, color='r', linestyle='--', alpha=0.7, label='95% threshold')\n",
                "axes[1].set_xlabel('Number of Components', fontsize=12)\n",
                "axes[1].set_ylabel('Cumulative Variance Explained', fontsize=12)\n",
                "axes[1].set_title('Cumulative Variance Explained', fontsize=13, fontweight='bold')\n",
                "axes[1].legend()\n",
                "axes[1].grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Observation**: First 2 PCs capture ~96% of variance!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Step 4: Transform Data to PC Space"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def transform_data(X, eigenvectors, n_components=2):\n",
                "    # Project onto top n_components\n",
                "    W = eigenvectors[:, :n_components]\n",
                "    X_transformed = X.dot(W)\n",
                "    return X_transformed\n",
                "\n",
                "# Reduce to 2D\n",
                "X_pca = transform_data(X_std, eigenvectors, n_components=2)\n",
                "\n",
                "print(f'Original shape: {X_std.shape}')\n",
                "print(f'Transformed shape: {X_pca.shape}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Visualize in 2D PC Space"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(10, 7))\n",
                "colors = ['red', 'blue', 'green']\n",
                "for i, color in enumerate(colors):\n",
                "    mask = y == i\n",
                "    plt.scatter(X_pca[mask, 0], X_pca[mask, 1], \n",
                "               c=color, label=iris.target_names[i], \n",
                "               alpha=0.7, edgecolors='k', s=50)\n",
                "\n",
                "plt.xlabel(f'PC1 ({var_exp[0]*100:.1f}% variance)', fontsize=12)\n",
                "plt.ylabel(f'PC2 ({var_exp[1]*100:.1f}% variance)', fontsize=12)\n",
                "plt.title('Iris Dataset in PC Space (Our PCA)', fontsize=14, fontweight='bold')\n",
                "plt.legend()\n",
                "plt.grid(True, alpha=0.3)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Complete PCA Function"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def pca_from_scratch(X, n_components=2):\n",
                "    \"\"\"\n",
                "    PCA implementation from scratch.\n",
                "    \n",
                "    Steps:\n",
                "    1. Standardize\n",
                "    2. Covariance matrix\n",
                "    3. Eigendecomposition\n",
                "    4. Sort and select top k\n",
                "    5. Transform\n",
                "    \"\"\"\n",
                "    # Standardize\n",
                "    X_std, mean, std = standardize(X)\n",
                "    \n",
                "    # Covariance\n",
                "    cov_matrix = compute_covariance_matrix(X_std)\n",
                "    \n",
                "    # Eigen\n",
                "    eigenvalues, eigenvectors = compute_eigen(cov_matrix)\n",
                "    \n",
                "    # Transform\n",
                "    X_transformed = transform_data(X_std, eigenvectors, n_components)\n",
                "    \n",
                "    return X_transformed, eigenvalues, eigenvectors, mean, std\n",
                "\n",
                "# Use it\n",
                "X_pca, eigenvals, eigenvecs, _, _ = pca_from_scratch(X, n_components=2)\n",
                "print(f'Transformed data shape: {X_pca.shape}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Compare with Scikit-Learn"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Our PCA\n",
                "our_pca, our_eigenvals, our_eigenvecs, _, _ = pca_from_scratch(X, n_components=2)\n",
                "\n",
                "# sklearn PCA\n",
                "sklearn_pca = SklearnPCA(n_components=2)\n",
                "sklearn_transformed = sklearn_pca.fit_transform(X)\n",
                "\n",
                "print('='*60)\n",
                "print('COMPARISON: OUR vs SKLEARN')\n",
                "print('='*60)\n",
                "print(f'Our explained variance:      {our_eigenvals[:2]}')\n",
                "print(f'sklearn explained variance:  {sklearn_pca.explained_variance_}')\n",
                "print(f'\\nOur variance ratio:          {our_eigenvals[:2] / np.sum(our_eigenvals)}')\n",
                "print(f'sklearn variance ratio:      {sklearn_pca.explained_variance_ratio_}')\n",
                "\n",
                "# Visual comparison\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
                "\n",
                "for i, color in enumerate(colors):\n",
                "    mask = y == i\n",
                "    axes[0].scatter(our_pca[mask, 0], our_pca[mask, 1], \n",
                "                   c=color, label=iris.target_names[i], alpha=0.7, edgecolors='k', s=50)\n",
                "    axes[1].scatter(sklearn_transformed[mask, 0], sklearn_transformed[mask, 1],\n",
                "                   c=color, label=iris.target_names[i], alpha=0.7, edgecolors='k', s=50)\n",
                "\n",
                "axes[0].set_title('Our PCA', fontsize=13, fontweight='bold')\n",
                "axes[0].set_xlabel('PC1', fontsize=11)\n",
                "axes[0].set_ylabel('PC2', fontsize=11)\n",
                "axes[0].legend()\n",
                "axes[0].grid(True, alpha=0.3)\n",
                "\n",
                "axes[1].set_title('Sklearn PCA', fontsize=13, fontweight='bold')\n",
                "axes[1].set_xlabel('PC1', fontsize=11)\n",
                "axes[1].set_ylabel('PC2', fontsize=11)\n",
                "axes[1].legend()\n",
                "axes[1].grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print('\\nNote: Directions may be flipped (eigenvectors have arbitrary sign) but patterns are identical!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Summary\n",
                "\n",
                "### PCA Algorithm:\n",
                "1. **Standardize** data (mean=0, std=1)\n",
                "2. **Compute covariance** matrix: $\\Sigma = \\frac{1}{m}X^TX$\n",
                "3. **Eigendecomposition**: Find eigenvalues and eigenvectors of $\\Sigma$\n",
                "4. **Sort** by eigenvalue (descending)\n",
                "5. **Select** top k eigenvectors\n",
                "6. **Transform**: $X_{PCA} = X \\cdot W_k$\n",
                "\n",
                "### What We get:\n",
                "- **Eigenvectors**: New axes (principal components)\n",
                "- **Eigenvalues**: Variance along each PC\n",
                "- **Transformed data**: Lower dimensional representation\n",
                "\n",
                "### Key Insights:\n",
                "- PC1 captures most variance\n",
                "- PCs are orthogonal (independent)\n",
                "- Can choose k to retain desired variance (e.g., 95%)\n",
                "- Standardization is CRITICAL!\n",
                "\n",
                "**Interview Tip**: \"PCA finds orthogonal directions of maximum variance by eigendecomposing the covariance matrix. The eigenvectors are the principal components, eigenvalues tell us variance explained. After standardizing, we compute the covariance matrix, find eigenvectors, and project data onto the top k components.\""
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}